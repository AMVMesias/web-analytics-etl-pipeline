<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas"/>
  <img src="https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white" alt="NumPy"/>
  <img src="https://img.shields.io/badge/Power_BI-F2C811?style=for-the-badge&logo=powerbi&logoColor=black" alt="PowerBI"/>
</p>

# üìä Pipeline ETL ‚Äî Web Analytics

Pipeline ETL de alto rendimiento construido en Python, dise√±ado para procesar y limpiar datasets masivos de anal√≠tica web (7 GB+). Maneja expansi√≥n de JSON, normalizaci√≥n de datos, detecci√≥n de outliers y generaci√≥n de reportes visuales ‚Äî todo optimizado para entornos con memoria limitada.

## üéØ Problema

Los datos crudos de herramientas como Google Analytics se exportan como archivos CSV con **columnas JSON anidadas**. Cada fila representa una visita de usuario, y los campos JSON contienen arrays de hits de p√°ginas, interacciones con productos y datos de fuentes de tr√°fico.

**Desaf√≠os:**
- Archivos de **7 GB+** ‚Äî no caben en memoria
- Columnas JSON con **arrays de longitud variable** (1 a 250+ hits por visita)
- Datos con **formato inconsistente**, problemas de encoding y JSON malformado
- Necesidad de aplanar, limpiar y preparar para dashboards en PowerBI

## üöÄ Soluci√≥n

El pipeline procesa datos en **lotes configurables**, usando I/O streaming y monitoreo de memoria para manejar archivos de cualquier tama√±o.

```
CSV Crudo (7 GB+)        CSV Limpio y Expandido          Dashboard PowerBI
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ visit_id     ‚îÇ         ‚îÇ visit_id         ‚îÇ            ‚îÇ  üìà Gr√°ficos ‚îÇ
‚îÇ hits (JSON)  ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ hit_1_page       ‚îÇ   ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫    ‚îÇ  üìä KPIs     ‚îÇ
‚îÇ traffic_src  ‚îÇ         ‚îÇ hit_1_time       ‚îÇ            ‚îÇ  üó∫Ô∏è Mapas    ‚îÇ
‚îÇ device (JSON)‚îÇ         ‚îÇ hit_2_page       ‚îÇ            ‚îÇ  üìã Tablas   ‚îÇ
‚îÇ ...          ‚îÇ         ‚îÇ device_browser   ‚îÇ            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ traffic_source   ‚îÇ
                         ‚îÇ ...              ‚îÇ
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Estructura del Proyecto

```
web-analytics-etl-pipeline/
‚îÇ
‚îú‚îÄ‚îÄ finalcsv.py            # Paso 1: Expansi√≥n JSON + detecci√≥n de outliers + reporte HTML
‚îú‚îÄ‚îÄ limpiezaFinal.py       # Paso 2: Limpieza y normalizaci√≥n del CSV expandido
‚îÇ
‚îú‚îÄ‚îÄ sample_data.csv        # Muestra de entrada (5 filas de referencia)
‚îú‚îÄ‚îÄ requirements.txt       # Dependencias Python
‚îú‚îÄ‚îÄ LICENSE
‚îî‚îÄ‚îÄ README.md
```

## ‚öôÔ∏è Componentes del Pipeline

### Paso 1: `finalcsv.py` ‚Äî Expansi√≥n JSON
- Lee el CSV en lotes configurables (por defecto: 1,000 filas)
- Detecta y normaliza columnas JSON (maneja comillas simples/dobles)
- Expande arrays de hits de longitud variable en columnas planas (`hit_1_page`, `hit_2_page`, ...)
- **Detecci√≥n de outliers**: Separa filas con conteos de hits anormalmente altos en un archivo aparte
- **Reporte HTML**: Visualizaci√≥n interactiva de la distribuci√≥n de hits
- **Output:** `visitas_expandidas_completo.csv` + `visitas_muchos_hits.csv` + reporte HTML

### Paso 2: `limpiezaFinal.py` ‚Äî Limpieza de Datos
Lee el CSV expandido del Paso 1 y aplica limpieza profunda:
- **Clase `EstadisticasLimpieza`**: Rastreo de todas las m√©tricas
- **Monitoreo de memoria**: Uso de RAM en tiempo real con `psutil`
- **Correcci√≥n de formatos de fecha**: Maneja m√∫ltiples formatos
- **Normalizaci√≥n de texto**: Limpieza de whitespace y encoding
- **Generaci√≥n de reportes**: JSON + texto formateado
- **Procesamiento resiliente**: Fallback l√≠nea por l√≠nea para CSVs malformados
- **Output:** `visitas_expandidas_completo_limpio.csv` (listo para Power BI)

## üîß Uso

### Instalaci√≥n

```bash
pip install -r requirements.txt
```

### Ejecutar el Pipeline

```bash
# Paso 1: Expansi√≥n JSON (genera visitas_expandidas_completo.csv)
python finalcsv.py

# Paso 2: Limpieza de datos (genera visitas_expandidas_completo_limpio.csv)
python limpiezaFinal.py
```

> **Nota:** Configurar las rutas de archivos de entrada/salida al inicio de cada script antes de ejecutar.

## üìà M√©tricas Clave

| M√©trica | Valor |
|---------|-------|
| **Tama√±o del archivo** | 7.6 GB |
| **Filas procesadas** | 1,000,000+ |
| **M√°ximo hits por visita** | 250+ |
| **Modo de procesamiento** | Por lotes (configurable) |
| **Monitoreo de memoria** | Tiempo real (psutil) |
| **Formatos de salida** | CSV, HTML, JSON, TXT |

## üõ†Ô∏è Tecnolog√≠as

| Tecnolog√≠a | Uso |
|---|---|
| **Python 3.8+** | Lenguaje principal |
| **Pandas** | Manipulaci√≥n de datos e I/O por lotes |
| **NumPy** | Operaciones num√©ricas |
| **Matplotlib + Seaborn** | Visualizaciones estad√≠sticas |
| **psutil** | Monitoreo de memoria y recursos |
| **tqdm** | Barras de progreso |
| **Power BI** | Visualizaci√≥n final en dashboards |

## üìù Licencia

Este proyecto est√° bajo la Licencia MIT ‚Äî ver el archivo [LICENSE](LICENSE) para m√°s detalles.
